#!/bin/bash
#SBATCH --job-name={{ job_name }}
#SBATCH --nodes={{ total_nodes }}
#SBATCH --ntasks={{ total_nodes }}
#SBATCH --ntasks-per-node=1
#SBATCH --account={{ account }}
#SBATCH --time={{ time_limit }}
#SBATCH --output=logs/%j/log.out
#SBATCH --error=logs/%j/log.err
#SBATCH --partition={{ partition }}

# Constants
PREFILL_NODES_PER_WORKER={{ prefill_nodes_per_worker }}
DECODE_NODES_PER_WORKER={{ decode_nodes_per_worker }}
TOTAL_PREFILL_NODES={{ total_prefill_nodes }}
TOTAL_DECODE_NODES={{ total_decode_nodes }}
PREFILL_WORKERS={{ prefill_workers }}
DECODE_WORKERS={{ decode_workers }}
TOTAL_NODES=$((TOTAL_PREFILL_NODES + TOTAL_DECODE_NODES))
GPUS_PER_NODE={{ gpus_per_node }}

# Remove validation since no division needed
# PREFILL_NODES_PER_WORKER and DECODE_NODES_PER_WORKER are direct inputs

LOG_DIR="${SLURM_SUBMIT_DIR}/logs/${SLURM_JOB_ID}/"
SCRIPT_DIR="${SLURM_SUBMIT_DIR}/scripts"
OUTPUT_DIR="${SLURM_SUBMIT_DIR}/outputs"
MODEL_DIR="{{ model_dir }}"
CONFIG_DIR="{{ config_dir }}"
CONTAINER_IMAGE="{{ container_image }}"
NETWORK_INTERFACE="{{ network_interface }}"
GPU_TYPE="{{ gpu_type | default('h100') }}"
USE_SGLANG_COMMANDS="{{ use_sglang_commands | default(false) }}"

{% raw %}

mkdir -p "${OUTPUT_DIR}" "${LOG_DIR}"

nodes=($(scontrol show hostnames $SLURM_NODELIST))
if [ ${#nodes[@]} -ne $TOTAL_NODES ]; then
    echo "Error: Expected $TOTAL_NODES nodes but got ${#nodes[@]} nodes"
    exit 1
fi

# Print node information
for i in "${!nodes[@]}"; do
    echo "Node $i: ${nodes[$i]}"
done

PREFILL_HOST_IP=$(srun --nodes=1 --ntasks=1 --nodelist=${nodes[0]} ip route get $(getent ahosts ${nodes[0]} | grep STREAM | head -1 | awk '{print $1}') | awk '{for(i=1;i<=NF;i++) if($i=="src") print $(i+1)}')
if [ -z "$PREFILL_HOST_IP" ]; then
    echo "Error: Could not retrieve IP address for prefill host ${nodes[0]} on interface $NETWORK_INTERFACE"
    exit 1
fi
echo "Prefill host IP address: $PREFILL_HOST_IP"

DECODE_HOST_IP=$(srun --nodes=1 --ntasks=1 --nodelist=${nodes[$TOTAL_PREFILL_NODES]} ip route get $(getent ahosts ${nodes[$TOTAL_PREFILL_NODES]} | grep STREAM | head -1 | awk '{print $1}') | awk '{for(i=1;i<=NF;i++) if($i=="src") print $(i+1)}')
if [ -z "$DECODE_HOST_IP" ]; then
    echo "Error: Could not retrieve IP address for decode host ${nodes[$TOTAL_PREFILL_NODES]} on interface $NETWORK_INTERFACE"
    exit 1
fi
echo "Decode host IP address: $DECODE_HOST_IP"

# Prepare enroot arguments to pass to srun commands
ENROOT_ARGS="\
    --container-image=${CONTAINER_IMAGE} \
    --no-container-entrypoint \
    --no-container-mount-home \
    --container-mounts=${MODEL_DIR}:/model/,${CONFIG_DIR}:/configs/,${SCRIPT_DIR}:/scripts/,${OUTPUT_DIR}:/outputs/,${LOG_DIR}:/logs/ \
"

# Build common worker arguments
WORKER_ARGS="--gpu_type ${GPU_TYPE} --gpus_per_node ${GPUS_PER_NODE}"
if [ "$USE_SGLANG_COMMANDS" = "True" ]; then
    WORKER_ARGS="${WORKER_ARGS} --use-sglang-commands"
fi

echo "Prefill: ${PREFILL_WORKERS} workers, ${PREFILL_NODES_PER_WORKER} nodes each"
echo "Decode: ${DECODE_WORKERS} workers, ${DECODE_NODES_PER_WORKER} nodes each"

# Launch prefill workers
prefill_global_rank=0
for worker_id in $(seq 0 $((PREFILL_WORKERS - 1))); do
    start_node=$((worker_id * PREFILL_NODES_PER_WORKER))
    end_node=$((start_node + PREFILL_NODES_PER_WORKER - 1))
    
    echo "Launching prefill worker ${worker_id} on nodes ${start_node}-${end_node}"
    
    # Launch tasks for this worker's nodes
    for i in $(seq $start_node $end_node); do
        node=${nodes[$i]}
        local_rank=$((i - start_node))  # 0,1,2... within each worker
        
        # Only the very first node globally should set up infrastructure
        global_rank_zero_flag=""
        if [ $prefill_global_rank -eq 0 ]; then
            global_rank_zero_flag="--is_global_rank_zero"
        fi
        
        echo "  Node ${i} (${node}): local_rank=${local_rank}, global_rank=${prefill_global_rank}"
        
        cmd="srun $ENROOT_ARGS --nodes=1 --ntasks=1 --nodelist=$node --output=${LOG_DIR}/${node}_prefill_w${worker_id}.out --error=${LOG_DIR}/${node}_prefill_w${worker_id}.err python /scripts/worker_setup.py --prefill_host_ip ${PREFILL_HOST_IP} --decode_host_ip ${DECODE_HOST_IP} --rank ${local_rank} --total_nodes ${PREFILL_NODES_PER_WORKER} --worker_type prefill ${global_rank_zero_flag} --gpu_utilization_log /logs/${node}_prefill_w${worker_id}_gpu_utilization.log ${WORKER_ARGS}"
        echo "$cmd"
        $cmd &
        
        prefill_global_rank=$((prefill_global_rank + 1))
    done
done

# Launch decode workers  
decode_global_rank=0
for worker_id in $(seq 0 $((DECODE_WORKERS - 1))); do
    start_node=$((TOTAL_PREFILL_NODES + worker_id * DECODE_NODES_PER_WORKER))
    end_node=$((start_node + DECODE_NODES_PER_WORKER - 1))
    
    echo "Launching decode worker ${worker_id} on nodes ${start_node}-${end_node}"
    
    for i in $(seq $start_node $end_node); do
        node=${nodes[$i]}
        local_rank=$((i - start_node))  # 0,1,2... within each worker
        
        echo "  Node ${i} (${node}): local_rank=${local_rank}, global_rank=${decode_global_rank}"
        
        cmd="srun $ENROOT_ARGS --nodes=1 --ntasks=1 --nodelist=$node --output=${LOG_DIR}/${node}_decode_w${worker_id}.out --error=${LOG_DIR}/${node}_decode_w${worker_id}.err python /scripts/worker_setup.py --decode_host_ip ${DECODE_HOST_IP} --prefill_host_ip ${PREFILL_HOST_IP} --rank ${local_rank} --total_nodes ${DECODE_NODES_PER_WORKER} --worker_type decode --gpu_utilization_log /logs/${node}_decode_w${worker_id}_gpu_utilization.log ${WORKER_ARGS}"
        echo "$cmd"
        $cmd &
        
        decode_global_rank=$((decode_global_rank + 1))
    done
done

echo ""
echo "To connect to the host prefill node:"
echo "srun $ENROOT_ARGS --jobid $SLURM_JOB_ID -w ${nodes[0]} --overlap --pty bash"

echo ""
echo "Make sure to cancel the job at the end:"
echo "scancel $SLURM_JOB_ID"

# Wait for all tasks to complete
wait
echo "Script finished at $(date)"

{% endraw %}

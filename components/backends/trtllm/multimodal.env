export MODALITY="multimodal"
#export IMAGE="gitlab-master.nvidia.com/dl/ai-dynamo/dynamo-ci:2f54a11213fc3bc1c80534c45081b5b74d75aa2d-33252043-tensorrtllm-arm64"
#export IMAGE="/lustre/share/core_dlfw_ci/rmccormick/images/dynamo33287805_trtllm_rc4.sqsh"
export IMAGE="/lustre/share/core_dlfw_ci/rmccormick/images/dynamo33252043_trtllm_rc6.sqsh"
export MOUNTS="${PWD}/:/mnt,/lustre:/lustre"
export MODEL_PATH="/lustre/fsw/core_dlfw_ci/kprashanth/meta-llama_Llama-4-Maverick-17B-128E-Instruct"
export SERVED_MODEL_NAME="meta-llama/Llama-4-Maverick-17B-128E-Instruct"
export NUM_PREFILL_NODES=2
export NUM_DECODE_NODES=2
export NUM_GPUS_PER_NODE=4
export PREFILL_ENGINE_CONFIG="/mnt/engine_configs/multimodal/llama4/prefill.yaml"
export DECODE_ENGINE_CONFIG="/mnt/engine_configs/multimodal/llama4/decode.yaml"

apiVersion: nvidia.com/v1alpha1
kind: DynamoGraphDeployment
metadata:
  name: disagg-router
spec:
  envs:
    - name: DYN_DEPLOYMENT_CONFIG
      value: '{"Common":{"model":"deepseek-ai/DeepSeek-R1-Distill-Llama-8B","block-size":64,"max-model-len":16384,"router":"kv","kv-transfer-config":"{\"kv_connector\":\"DynamoNixlConnector\"}"},"Frontend":{"served_model_name":"deepseek-ai/DeepSeek-R1-Distill-Llama-8B","endpoint":"dynamo.Processor.chat/completions","port":8000},"Processor":{"common-configs":["model","block-size","max-model-len","router"]},"Router":{"min-workers":1,"common-configs":["model","block-size","router"]},"VllmWorker":{"max-num-batched-tokens":16384,"remote-prefill":true,"conditional-disagg":true,"max-local-prefill-length":10,"max-prefill-queue-size":2,"tensor-parallel-size":1,"enable-prefix-caching":true,"ServiceArgs":{"workers":1,"resources":{"gpu":"1"}},"common-configs":["model","block-size","max-model-len","router","kv-transfer-config"]},"PrefillWorker":{"max-num-batched-tokens":16384,"ServiceArgs":{"workers":1,"resources":{"gpu":"1"}},"common-configs":["model","block-size","max-model-len","kv-transfer-config"]},"Planner":{"environment":"kubernetes","no-operation":true}}'
  services:
    Frontend:
      dynamoNamespace: llm-disagg-router
      componentType: main
      replicas: 1
      resources:
        requests:
          cpu: "1"
          memory: "2Gi"
        limits:
          cpu: "1"
          memory: "2Gi"
      extraPodSpec:
        mainContainer:
          image: nvcr.io/nvidia/ai-dynamo/vllm-runtime:0.3.1
          workingDir: /workspace/examples/llm
          args:
            - dynamo
            - serve
            - graphs.disagg_router:Frontend
            - --system-app-port
            - "5000"
            - --enable-system-app
            - --use-default-health-checks
            - --service-name
            - Frontend
    Processor:
      dynamoNamespace: llm-disagg-router
      componentType: worker
      replicas: 1
      resources:
        requests:
          cpu: "1"
          memory: "2Gi"
        limits:
          cpu: "1"
          memory: "2Gi"
      extraPodSpec:
        mainContainer:
          image: nvcr.io/nvidia/ai-dynamo/vllm-runtime:0.3.1
          workingDir: /workspace/examples/llm
          args:
            - dynamo
            - serve
            - graphs.disagg_router:Processor
            - --system-app-port
            - "5000"
            - --enable-system-app
            - --use-default-health-checks
            - --service-name
            - Processor
    Router:
      dynamoNamespace: llm-disagg-router
      componentType: worker
      replicas: 1
      resources:
        requests:
          cpu: "1"
          memory: "2Gi"
        limits:
          cpu: "1"
          memory: "2Gi"
      extraPodSpec:
        mainContainer:
          image: nvcr.io/nvidia/ai-dynamo/vllm-runtime:0.3.1
          workingDir: /workspace/examples/llm
          args:
            - dynamo
            - serve
            - graphs.disagg_router:Router
            - --system-app-port
            - "5000"
            - --enable-system-app
            - --use-default-health-checks
            - --service-name
            - Router
    VllmWorker:
      envFromSecret: hf-token-secret
      dynamoNamespace: llm-disagg-router
      replicas: 1
      resources:
        requests:
          cpu: "10"
          memory: "20Gi"
          gpu: "1"
        limits:
          cpu: "10"
          memory: "20Gi"
          gpu: "1"
      extraPodSpec:
        mainContainer:
          image: nvcr.io/nvidia/ai-dynamo/vllm-runtime:0.3.1
          workingDir: /workspace/examples/llm
          args:
            - dynamo
            - serve
            - graphs.disagg_router:VllmWorker
            - --system-app-port
            - "5000"
            - --enable-system-app
            - --use-default-health-checks
            - --service-name
            - VllmWorker
    PrefillWorker:
      envFromSecret: hf-token-secret
      dynamoNamespace: llm-disagg-router
      replicas: 1
      resources:
        requests:
          cpu: "10"
          memory: "20Gi"
          gpu: "1"
        limits:
          cpu: "10"
          memory: "20Gi"
          gpu: "1"
      extraPodSpec:
        mainContainer:
          image: nvcr.io/nvidia/ai-dynamo/vllm-runtime:0.3.1
          workingDir: /workspace/examples/llm
          args:
            - dynamo
            - serve
            - graphs.disagg_router:PrefillWorker
            - --system-app-port
            - "5000"
            - --enable-system-app
            - --use-default-health-checks
            - --service-name
            - PrefillWorker

apiVersion: nvidia.com/v1alpha1
kind: DynamoGraphDeployment
metadata:
  name: llm-agg
spec:
  envs:
    - name: DYN_DEPLOYMENT_CONFIG
      value: '{"Common":{"model":"deepseek-ai/DeepSeek-R1-Distill-Llama-8B","block-size":64,"max-model-len":16384},"Frontend":{"served_model_name":"deepseek-ai/DeepSeek-R1-Distill-Llama-8B","endpoint":"dynamo.Processor.chat/completions","port":8000},"Processor":{"router":"round-robin","router-num-threads":4,"common-configs":["model","block-size","max-model-len"]},"VllmWorker":{"enforce-eager":true,"max-num-batched-tokens":16384,"enable-prefix-caching":true,"ServiceArgs":{"workers":1,"resources":{"gpu":"1"}},"common-configs":["model","block-size","max-model-len"]},"Planner":{"environment":"kubernetes","no-operation":true}}'
  services:
    Frontend:
      dynamoNamespace: llm-agg
      componentType: main
      replicas: 1
      resources:
        requests:
          cpu: "1"
          memory: "2Gi"
        limits:
          cpu: "1"
          memory: "2Gi"
      extraPodSpec:
        mainContainer:
          image: nvcr.io/nvidia/ai-dynamo/vllm-runtime:0.3.1
          args:
            - cd
            - /workspace/examples/llm
            - "&&"
            - dynamo
            - serve
            - graphs.agg:Frontend
            - --system-app-port
            - "5000"
            - --enable-system-app
            - --use-default-health-checks
            - --service-name
            - Frontend
    Processor:
      dynamoNamespace: llm-agg
      componentType: worker
      replicas: 1
      resources:
        requests:
          cpu: "1"
          memory: "2Gi"
        limits:
          cpu: "1"
          memory: "2Gi"
      extraPodSpec:
        mainContainer:
          image: nvcr.io/nvidia/ai-dynamo/vllm-runtime:0.3.1
          args:
            - cd
            - /workspace/examples/llm
            - "&&"
            - dynamo
            - serve
            - graphs.agg:Processor
            - --system-app-port
            - "5000"
            - --enable-system-app
            - --use-default-health-checks
            - --service-name
            - Processor
    VllmWorker:
      envFromSecret: hf-token-secret
      dynamoNamespace: llm-agg
      replicas: 1
      resources:
        requests:
          cpu: "10"
          memory: "20Gi"
          gpu: "1"
        limits:
          cpu: "10"
          memory: "20Gi"
          gpu: "1"
      extraPodSpec:
        mainContainer:
          image: nvcr.io/nvidia/ai-dynamo/vllm-runtime:0.3.1
          args:
            - cd
            - /workspace/examples/llm
            - "&&"
            - dynamo
            - serve
            - graphs.agg:VllmWorker
            - --system-app-port
            - "5000"
            - --enable-system-app
            - --use-default-health-checks
            - --service-name
            - VllmWorker
